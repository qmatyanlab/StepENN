{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import e3nn\n",
    "import ase\n",
    "import ase.neighborlist\n",
    "import torch_geometric\n",
    "import torch_geometric.data\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of `notebook/` to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "default_dtype = torch.float64\n",
    "torch.set_default_dtype(default_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms(symbols='Po', pbc=True, cell=[3.34, 3.34, 3.34])\n",
      "Atoms(symbols='Si2', pbc=True, cell=[[0.0, 2.734364, 2.734364], [2.734364, 0.0, 2.734364], [2.734364, 2.734364, 0.0]])\n"
     ]
    }
   ],
   "source": [
    "# A lattice is a 3 x 3 matrix\n",
    "# The first index is the lattice vector (a, b, c)\n",
    "# The second index is a Cartesian index over (x, y, z)\n",
    "\n",
    "# Polonium with Simple Cubic Lattice\n",
    "po_lattice = torch.eye(3) * 3.340  # Cubic lattice with edges of length 3.34 AA\n",
    "po_coords = torch.tensor([[0., 0., 0.,]])\n",
    "po_types = ['Po']\n",
    "\n",
    "# Silicon with Diamond Structure\n",
    "si_lattice = torch.tensor([\n",
    "    [0.      , 2.734364, 2.734364],\n",
    "    [2.734364, 0.      , 2.734364],\n",
    "    [2.734364, 2.734364, 0.      ]\n",
    "])\n",
    "si_coords = torch.tensor([\n",
    "    [1.367182, 1.367182, 1.367182],\n",
    "    [0.      , 0.      , 0.      ]\n",
    "])\n",
    "si_types = ['Si', 'Si']\n",
    "\n",
    "po = ase.Atoms(symbols=po_types, positions=po_coords, cell=po_lattice, pbc=True)\n",
    "si = ase.Atoms(symbols=si_types, positions=si_coords, cell=si_lattice, pbc=True)\n",
    "print(po)\n",
    "print(si)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use the ase.neighborlist.neighbor_list algorithm and a radial_cutoff distance to define which edges to include in the graph to represent interactions with neighboring atoms. Note that for a convolutional network, the number of layers determines the receptive field, i.e. how “far out” any given atom can see. So even if a we use a radial_cutoff = 3.5, a two layer network effectively sees 2 * 3.5 = 7 distance units (in this case Angstroms) away and a three layer network 3 * 3.5 = 10.5 distance units. We then store our data in torch_geometric.data.Data objects that we will batch with torch_geometric.data.DataLoader below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[1, 2], edge_index=[2, 7], pos=[1, 3], lattice=[1, 3, 3], edge_shift=[7, 3], energy=[1, 1]), Data(x=[2, 2], edge_index=[2, 10], pos=[2, 3], lattice=[1, 3, 3], edge_shift=[10, 3], energy=[1, 1])]\n"
     ]
    }
   ],
   "source": [
    "radial_cutoff = 3.5  # Only include edges for neighboring atoms within a radius of 3.5 Angstroms.\n",
    "type_encoding = {'Po': 0, 'Si': 1}\n",
    "type_onehot = torch.eye(len(type_encoding))\n",
    "\n",
    "dataset = []\n",
    "\n",
    "dummy_energies = torch.randn(2, 1, 1)  # dummy energies for example\n",
    "\n",
    "for crystal, energy in zip([po, si], dummy_energies):\n",
    "    # edge_src and edge_dst are the indices of the central and neighboring atom, respectively\n",
    "    # edge_shift indicates whether the neighbors are in different images / copies of the unit cell\n",
    "    edge_src, edge_dst, edge_shift = ase.neighborlist.neighbor_list(\"ijS\", a=crystal, cutoff=radial_cutoff, self_interaction=True)\n",
    "    # print(edge_src)\n",
    "    # print(edge_dst)\n",
    "    # print(edge_shift)\n",
    "    data = torch_geometric.data.Data(\n",
    "        pos=torch.tensor(crystal.get_positions()),\n",
    "        lattice=torch.tensor(crystal.cell.array).unsqueeze(0),  # We add a dimension for batching\n",
    "        x=type_onehot[[type_encoding[atom] for atom in crystal.symbols]],  # Using \"dummy\" inputs of scalars because they are all C\n",
    "        edge_index=torch.stack([torch.LongTensor(edge_src), torch.LongTensor(edge_dst)], dim=0),\n",
    "        edge_shift=torch.tensor(edge_shift, dtype=default_dtype),\n",
    "        energy=energy  # dummy energy (assumed to be normalized \"per atom\")\n",
    "    )\n",
    "\n",
    "    dataset.append(data)\n",
    "\n",
    "print(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[3, 2], edge_index=[2, 17], pos=[3, 3], lattice=[2, 3, 3], edge_shift=[17, 3], energy=[2, 1], batch=[3], ptr=[3])\n",
      "tensor([0, 1, 1])\n",
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [1.3672, 1.3672, 1.3672],\n",
      "        [0.0000, 0.0000, 0.0000]])\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "dataloader = torch_geometric.data.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "for data in dataloader:\n",
    "    print(data)\n",
    "    print(data.batch)\n",
    "    print(data.pos)\n",
    "    print(data.x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the vectors associated with each edge for a given torch_geometric.data.Data object representing a single example, we use the following expression:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_src, edge_dst = data['edge_index'][0], data['edge_index'][1]\n",
    "# print(data['pos'][edge_dst] - data['pos'][edge_src])\n",
    "# print(data['edge_shift'])\n",
    "# edge_vec = (data['pos'][edge_dst] - data['pos'][edge_src]\n",
    "#             + torch.einsum('ni,nij->nj', data['edge_shift'], data['lattice'])) \n",
    "# print(edge_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from e3nn.nn.models.v2103.gate_points_networks import SimpleNetwork\n",
    "# from e3nn.nn.models.gate_points_2101 import Network\n",
    "from utils_model.gate_points_networks import SimpleNetwork\n",
    "\n",
    "from typing import Dict, Union\n",
    "import torch_scatter\n",
    "\n",
    "class SimplePeriodicNetwork(SimpleNetwork):\n",
    "# class SimplePeriodicNetwork(Network):\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        \"\"\"The keyword `pool_nodes` is used by SimpleNetwork to determine\n",
    "        whether we sum over all atom contributions per example. In this example,\n",
    "        we want use a mean operations instead, so we will override this behavior.\n",
    "        \"\"\"\n",
    "        self.pool = False\n",
    "        if kwargs['pool_nodes'] == True:\n",
    "            kwargs['pool_nodes'] = False\n",
    "            kwargs['num_nodes'] = 1.\n",
    "            self.pool = True\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    # Overwriting preprocess method of SimpleNetwork to adapt for periodic boundary data\n",
    "    def preprocess(self, data: Union[torch_geometric.data.Data, Dict[str, torch.Tensor]]) -> torch.Tensor:\n",
    "        if 'batch' in data:\n",
    "            batch = data['batch']\n",
    "        else:\n",
    "            batch = data['pos'].new_zeros(data['pos'].shape[0], dtype=torch.long)\n",
    "\n",
    "        edge_src = data['edge_index'][0]  # Edge source\n",
    "        edge_dst = data['edge_index'][1]  # Edge destination\n",
    "\n",
    "        # We need to compute this in the computation graph to backprop to positions\n",
    "        # We are computing the relative distances + unit cell shifts from periodic boundaries\n",
    "        edge_batch = batch[edge_src]\n",
    "        edge_vec = (data['pos'][edge_dst]\n",
    "                    - data['pos'][edge_src]\n",
    "                    + torch.einsum('ni,nij->nj', data['edge_shift'], data['lattice'][edge_batch]))\n",
    "\n",
    "        return batch, data['x'], edge_src, edge_dst, edge_vec\n",
    "\n",
    "    def forward(self, data: Union[torch_geometric.data.Data, Dict[str, torch.Tensor]]) -> torch.Tensor:\n",
    "        # if pool_nodes was set to True, use scatter_mean to aggregate\n",
    "        output = super().forward(data)\n",
    "        if self.pool == True:\n",
    "\n",
    "            return torch_scatter.scatter_mean(output, data.batch, dim=0)  # Take mean over atoms per example\n",
    "        \n",
    "        else:\n",
    "            return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimplePeriodicNetwork(\n",
    "    irreps_in=\"64x0e\",  # One hot scalars (L=0 and even parity) on each atom to represent atom type\n",
    "    irreps_out=\"200x0e\",  # Single scalar (L=0 and even parity) to output (for example) energy\n",
    "    max_radius=radial_cutoff, # Cutoff radius for convolution\n",
    "    layers = 3,\n",
    "    lmax = 3,\n",
    "    num_neighbors=10.0,  # scaling factor based on the typical number of neighbors\n",
    "    pool_nodes=True,  # We pool nodes to predict total energy\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimplePeriodicNetwork(\n",
      "  (mp): MessagePassing(\n",
      "    (layers): ModuleList(\n",
      "      (0): Compose(\n",
      "        (first): Convolution(\n",
      "          (sc): FullyConnectedTensorProduct(64x0e x 1x0e -> 200x0e+50x1o+50x2e+50x3o | 12800 paths | 12800 weights)\n",
      "          (lin1): FullyConnectedTensorProduct(64x0e x 1x0e -> 64x0e | 4096 paths | 4096 weights)\n",
      "          (fc): FullyConnectedNet[10, 100, 256]\n",
      "          (tp): TensorProduct(64x0e x 1x0e+1x1o+1x2e+1x3o -> 64x0e+64x1o+64x2e+64x3o | 256 paths | 256 weights)\n",
      "          (lin2): FullyConnectedTensorProduct(64x0e+64x1o+64x2e+64x3o x 1x0e -> 200x0e+50x1o+50x2e+50x3o | 22400 paths | 22400 weights)\n",
      "          (lin3): FullyConnectedTensorProduct(64x0e+64x1o+64x2e+64x3o x 1x0e -> 1x0e | 64 paths | 64 weights)\n",
      "        )\n",
      "        (second): Gate (200x0e+50x1o+50x2e+50x3o -> 50x0e+50x1o+50x2e+50x3o)\n",
      "      )\n",
      "      (1): Compose(\n",
      "        (first): Convolution(\n",
      "          (sc): FullyConnectedTensorProduct(50x0e+50x1o+50x2e+50x3o x 1x0e -> 350x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e | 25000 paths | 25000 weights)\n",
      "          (lin1): FullyConnectedTensorProduct(50x0e+50x1o+50x2e+50x3o x 1x0e -> 50x0e+50x1o+50x2e+50x3o | 10000 paths | 10000 weights)\n",
      "          (fc): FullyConnectedNet[10, 100, 1700]\n",
      "          (tp): TensorProduct(50x0e+50x1o+50x2e+50x3o x 1x0e+1x1o+1x2e+1x3o -> 200x0e+300x1o+150x1e+200x2o+350x2e+300x3o+200x3e | 1700 paths | 1700 weights)\n",
      "          (lin2): FullyConnectedTensorProduct(200x0e+300x1o+150x1e+200x2o+350x2e+300x3o+200x3e x 1x0e -> 350x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e | 145000 paths | 145000 weights)\n",
      "          (lin3): FullyConnectedTensorProduct(200x0e+300x1o+150x1e+200x2o+350x2e+300x3o+200x3e x 1x0e -> 1x0e | 200 paths | 200 weights)\n",
      "        )\n",
      "        (second): Gate (350x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e -> 50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e)\n",
      "      )\n",
      "      (2): Compose(\n",
      "        (first): Convolution(\n",
      "          (sc): FullyConnectedTensorProduct(50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e x 1x0e -> 50x0o+350x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e | 32500 paths | 32500 weights)\n",
      "          (lin1): FullyConnectedTensorProduct(50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e x 1x0e -> 50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e | 17500 paths | 17500 weights)\n",
      "          (fc): FullyConnectedNet[10, 100, 3200]\n",
      "          (tp): TensorProduct(50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e x 1x0e+1x1o+1x2e+1x3o -> 150x0o+200x0e+450x1o+400x1e+500x2o+550x2e+500x3o+450x3e | 3200 paths | 3200 weights)\n",
      "          (lin2): FullyConnectedTensorProduct(150x0o+200x0e+450x1o+400x1e+500x2o+550x2e+500x3o+450x3e x 1x0e -> 50x0o+350x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e | 220000 paths | 220000 weights)\n",
      "          (lin3): FullyConnectedTensorProduct(150x0o+200x0e+450x1o+400x1e+500x2o+550x2e+500x3o+450x3e x 1x0e -> 1x0e | 200 paths | 200 weights)\n",
      "        )\n",
      "        (second): Gate (50x0o+350x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e -> 50x0o+50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e)\n",
      "      )\n",
      "      (3): Convolution(\n",
      "        (sc): FullyConnectedTensorProduct(50x0o+50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e x 1x0e -> 200x0e | 10000 paths | 10000 weights)\n",
      "        (lin1): FullyConnectedTensorProduct(50x0o+50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e x 1x0e -> 50x0o+50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e | 20000 paths | 20000 weights)\n",
      "        (fc): FullyConnectedNet[10, 100, 200]\n",
      "        (tp): TensorProduct(50x0o+50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e x 1x0e+1x1o+1x2e+1x3o -> 200x0e | 200 paths | 200 weights)\n",
      "        (lin2): FullyConnectedTensorProduct(200x0e x 1x0e -> 200x0e | 40000 paths | 40000 weights)\n",
      "        (lin3): FullyConnectedTensorProduct(200x0e x 1x0e -> 1x0e | 200 paths | 200 weights)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Incorrect last dimension for x",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# One scalar per example\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[94], line 43\u001b[0m, in \u001b[0;36mSimplePeriodicNetwork.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Union[torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData, Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# if pool_nodes was set to True, use scatter_mean to aggregate\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch_scatter\u001b[38;5;241m.\u001b[39mscatter_mean(output, data\u001b[38;5;241m.\u001b[39mbatch, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Take mean over atoms per example\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/materialProject/refined_structure/utils_model/gate_points_networks.py:90\u001b[0m, in \u001b[0;36mSimpleNetwork.forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     78\u001b[0m edge_length_embedding \u001b[38;5;241m=\u001b[39m soft_one_hot_linspace(\n\u001b[1;32m     79\u001b[0m     edge_length,\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# cutoff=True,  # no need for an additional smooth cutoff\u001b[39;00m\n\u001b[1;32m     87\u001b[0m )\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_basis\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Node attributes are not used here\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m node_attr \u001b[38;5;241m=\u001b[39m node_inputs\u001b[38;5;241m.\u001b[39mnew_ones(node_inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     92\u001b[0m node_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp(node_inputs, node_attr, edge_src, edge_dst, edge_attr, edge_length_embedding)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_nodes:\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/materialProject/refined_structure/utils_model/gate_points_message_passing.py:134\u001b[0m, in \u001b[0;36mMessagePassing.forward\u001b[0;34m(self, node_features, node_attr, edge_src, edge_dst, edge_attr, edge_scalars)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_features, node_attr, edge_src, edge_dst, edge_attr, edge_scalars) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lay \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 134\u001b[0m         node_features \u001b[38;5;241m=\u001b[39m \u001b[43mlay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_dst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_scalars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node_features\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/materialProject/refined_structure/utils_model/gate_points_message_passing.py:30\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecond(x)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/materialProject/refined_structure/utils_model/points_convolution.py:81\u001b[0m, in \u001b[0;36mConvolution.forward\u001b[0;34m(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     79\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(edge_scalars)\n\u001b[0;32m---> 81\u001b[0m     node_self_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     node_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(node_input, node_attr)\n\u001b[1;32m     84\u001b[0m     edge_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtp(node_features[edge_src], edge_attr, weight)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/e3nn/o3/_tensor_product/_tensor_product.py:549\u001b[0m, in \u001b[0;36mTensorProduct.forward\u001b[0;34m(self, x, y, weight)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, weight: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate :math:`w x \\otimes y`.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m        tensor of shape ``(..., irreps_out.dim)``\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_in1_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIncorrect last dimension for x\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_assert(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in2_dim, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect last dimension for y\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;66;03m# - PROFILER - with torch.autograd.profiler.record_function(self._profiling_str):\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/__init__.py:1209\u001b[0m, in \u001b[0;36m_assert\u001b[0;34m(condition, message)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(condition) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;129;01mand\u001b[39;00m has_torch_function((condition,)):\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(_assert, (condition,), condition, message)\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m condition, message\n",
      "\u001b[0;31mAssertionError\u001b[0m: Incorrect last dimension for x"
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    print(net(data).shape)  # One scalar per example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Incorrect last dimension for x",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[94], line 43\u001b[0m, in \u001b[0;36mSimplePeriodicNetwork.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Union[torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData, Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# if pool_nodes was set to True, use scatter_mean to aggregate\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch_scatter\u001b[38;5;241m.\u001b[39mscatter_mean(output, data\u001b[38;5;241m.\u001b[39mbatch, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Take mean over atoms per example\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/materialProject/refined_structure/utils_model/gate_points_networks.py:90\u001b[0m, in \u001b[0;36mSimpleNetwork.forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     78\u001b[0m edge_length_embedding \u001b[38;5;241m=\u001b[39m soft_one_hot_linspace(\n\u001b[1;32m     79\u001b[0m     edge_length,\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# cutoff=True,  # no need for an additional smooth cutoff\u001b[39;00m\n\u001b[1;32m     87\u001b[0m )\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_basis\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Node attributes are not used here\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m node_attr \u001b[38;5;241m=\u001b[39m node_inputs\u001b[38;5;241m.\u001b[39mnew_ones(node_inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     92\u001b[0m node_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp(node_inputs, node_attr, edge_src, edge_dst, edge_attr, edge_length_embedding)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_nodes:\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/materialProject/refined_structure/utils_model/gate_points_message_passing.py:134\u001b[0m, in \u001b[0;36mMessagePassing.forward\u001b[0;34m(self, node_features, node_attr, edge_src, edge_dst, edge_attr, edge_scalars)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_features, node_attr, edge_src, edge_dst, edge_attr, edge_scalars) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lay \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 134\u001b[0m         node_features \u001b[38;5;241m=\u001b[39m \u001b[43mlay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_dst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_scalars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node_features\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/materialProject/refined_structure/utils_model/gate_points_message_passing.py:30\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecond(x)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/materialProject/refined_structure/utils_model/points_convolution.py:81\u001b[0m, in \u001b[0;36mConvolution.forward\u001b[0;34m(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_scalars) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     79\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(edge_scalars)\n\u001b[0;32m---> 81\u001b[0m     node_self_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     node_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(node_input, node_attr)\n\u001b[1;32m     84\u001b[0m     edge_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtp(node_features[edge_src], edge_attr, weight)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/e3nn/o3/_tensor_product/_tensor_product.py:549\u001b[0m, in \u001b[0;36mTensorProduct.forward\u001b[0;34m(self, x, y, weight)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, weight: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate :math:`w x \\otimes y`.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m        tensor of shape ``(..., irreps_out.dim)``\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_in1_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIncorrect last dimension for x\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_assert(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in2_dim, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect last dimension for y\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;66;03m# - PROFILER - with torch.autograd.profiler.record_function(self._profiling_str):\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m225/angush/python_venv/pytorch_env/lib/python3.11/site-packages/torch/__init__.py:1209\u001b[0m, in \u001b[0;36m_assert\u001b[0;34m(condition, message)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(condition) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;129;01mand\u001b[39;00m has_torch_function((condition,)):\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(_assert, (condition,), condition, message)\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m condition, message\n",
      "\u001b[0;31mAssertionError\u001b[0m: Incorrect last dimension for x"
     ]
    }
   ],
   "source": [
    "print(net(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
